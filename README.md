# Классификация токсичных комментариев для интернет-магазина «Викишоп»

![Python](https://img.shields.io/badge/Python-3.9-3776AB?logo=python&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-2.4.2-013243?logo=numpy&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-3.0.1-150458?logo=pandas&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-3.8.0-11557c?logo=matplotlib&logoColor=white)
![Seaborn](https://img.shields.io/badge/Seaborn-0.13.2-4c72b0?logo=python&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.8.0-F7931E?logo=scikit-learn&logoColor=white)
![CatBoost](https://img.shields.io/badge/CatBoost-1.2.8-ff4b4b?logo=catboost&logoColor=white)
![NLTK](https://img.shields.io/badge/NLTK-3.9.1-154f5c?logo=python&logoColor=white)
![Transformers](https://img.shields.io/badge/Transformers-4.44.2-FFD21E?logo=huggingface&logoColor=black)
![PyTorch](https://img.shields.io/badge/PyTorch-2.2.2-EE4C2C?logo=pytorch&logoColor=white)
![Imbalanced-learn](https://img.shields.io/badge/imbalanced--learn-0.14.1-1676c7?logo=python&logoColor=white)
![tqdm](https://img.shields.io/badge/tqdm-4.67.3-FF6F61?logo=python&logoColor=white)

## Описание проекта

Интернет‑магазин «Викишоп» внедряет вики‑систему для совместного редактирования описаний товаров. Чтобы поддерживать конструктивную среду и оперативно реагировать на нарушения, необходимо автоматически определять токсичные комментарии (правки) и отправлять их на модерацию. В проекте разрабатывается модель машинного обучения, способная отличать токсичные высказывания от безопасных.

**Цель:** Построить модель бинарной классификации (токсичный / не токсичный) с целевой метрикой **F1 ≥ 0.75**, чтобы автоматически выявлять комментарии, требующие проверки модератором, и минимизировать ручную обработку.

## Данные

В распоряжении имеется датасет с комментариями пользователей, размеченными вручную. Каждая запись содержит текст комментария и бинарную метку `toxic` (1 – токсичный, 0 – нетоксичный). Данные несбалансированы: доля токсичных комментариев составляет около 10%.

- Источник: соревнование [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) (адаптированная версия).
- Исходный файл: `toxic_comments.zip` (архив). Перед запуском необходимо распаковать архив и поместить файл `toxic_comments.csv` в папку `data/` (или в корневую директорию, в зависимости от настройки).
- Для ускорения повторных экспериментов в репозитории предоставляется файл с уже очищенным текстом **`data_clean_text.csv`**. Если этот файл присутствует в рабочей директории, код автоматически загрузит его, пропуская длительный этап предобработки (около 2 часов). В противном случае выполняется полная очистка, лемматизация и удаление стоп‑слов.

## Этапы работы

1. **Исследовательский анализ данных (EDA)**
   - Проверка пропусков, дубликатов, распределение классов.
   - Генерация числовых характеристик текста (длина, количество слов, доля заглавных букв, знаки препинания).
   - Корреляционный анализ с целевой переменной.

2. **Предобработка текста**
   - Очистка от специальных символов, приведение к нижнему регистру.
   - Удаление стоп‑слов (NLTK) и лемматизация с учётом частей речи (WordNetLemmatizer).

3. **Разделение данных**
   - Обучающая, валидационная и тестовая выборки в пропорции 60/20/20 со стратификацией по целевой переменной.

4. **Базовая модель**
   - `DummyClassifier` (стратифицированный) для установления нижней границы качества (F1 ≈ 0.096).

5. **Классические модели с TF‑IDF**
   - Логистическая регрессия, случайный лес, CatBoost.
   - Подбор гиперпараметров через `RandomizedSearchCV` с оптимизацией F1.

6. **BERT как экстрактор признаков**
   - Использование предобученной модели `unitary/toxic-bert` для получения эмбеддингов комментариев (768‑мерные векторы).
   - Обучение логистической регрессии на полученных эмбеддингах с применением **SMOTE** для борьбы с дисбалансом.

7. **Сравнение моделей и финальная оценка**
   - Сравнение всех моделей по F1 на валидационной выборке.
   - Выбор лучшей модели и проверка на тестовой выборке.

## Используемые технологии

- **Python** — основной язык.
- **Pandas, NumPy** — обработка и анализ данных.
- **Matplotlib, Seaborn** — визуализация.
- **NLTK** — предобработка текста (стоп‑слова, лемматизация).
- **Scikit‑learn** — TF‑IDF, классические модели, пайплайны, метрики.
- **CatBoost** — градиентный бустинг.
- **Transformers, PyTorch** — загрузка BERT, получение эмбеддингов.
- **Imbalanced‑learn** — SMOTE.
- **tqdm** — прогресс‑бары при обработке.
- **Jupyter Notebook** — среда разработки.

## Результаты

| Модель                          | F1 (валидация) | Примечание                                 |
|---------------------------------|----------------|--------------------------------------------|
| DummyClassifier                 | 0.096          | Стратифицированный                         |
| LogisticRegression + TF‑IDF     | 0.764          |                                             |
| RandomForest + TF‑IDF           | 0.661          |                                             |
| CatBoost + TF‑IDF               | 0.731          |                                             |
| **BERT + SMOTE + LogisticRegression** | **0.947** | Эмбеддинги BERT + синтез данных SMOTE |

Лучшая модель — **логистическая регрессия на эмбеддингах BERT с SMOTE** — достигла на тестовой выборке значения **F1 = 0.9473**, значительно превысив целевой порог (0.75).

**Метрики на тесте (лучшая модель):**
- Точность (toxic): 0.90  
- Полнота (toxic): 1.00  
- F1 (toxic): 0.95  
- Матрица ошибок:  
  - Истинно нетоксичные: 71 (TN), ложноположительные: 0  
  - Истинно токсичные: 9 (TP), ложноотрицательные: 0  

## Выводы

Разработанная модель может быть интегрирована в систему модерации контента «Викишоп» для автоматического выявления токсичных комментариев. Ожидаемый эффект:

- Снижение нагрузки на модераторов на **75–80%**.
- Ускорение публикации безопасных правок.
- Уменьшение репутационных рисков и поддержание доброжелательной атмосферы.

**Ключевые факторы успеха:**
- Использование предобученной модели BERT (специализированной на токсичности) для извлечения семантических признаков.
- Применение SMOTE для балансировки классов.
- Тщательная предобработка текста (лемматизация, удаление стоп‑слов).

## Запуск проекта

1. Клонируйте репозиторий:
   ```bash
   git clone https://github.com/arseniybartenev/wikishop-toxic-comments-classification.git
   ```
2. Перейдите в папку проекта:
   ```bash
   cd wikishop-toxic-comments-classification
   ```
3. Установите зависимости:
   ```bash
   pip install -r requirements.txt
   ```
4. Подготовьте данные:
   - Распакуйте архив `toxic_comments.zip` и поместите файл `toxic_comments.csv` в папку `data/` (или в корневую директорию).
   - (Опционально) Для ускорения работы скопируйте предоставленный файл `data_clean_text.csv` в рабочую директорию. При его наличии код автоматически загрузит очищенный текст, минуя длительный этап предобработки.
5. Запустите Jupyter Notebook:
   ```bash
   jupyter notebook notebooks/classification_of_toxic_comments.ipynb
   ```

## Структура репозитория

```
classification_of_toxic_comments/
├── data/                               # Папка для данных
│   └── toxic_comments.csv              # (нужно распаковать из архива)
├── notebooks/                          # Jupyter ноутбук с полным анализом
│   └── classification_of_toxic_comments.ipynb
├── data_clean_text.csv                 # Очищенный текст (опционально, для ускорения)
├── README.md                           # Этот файл
└── requirements.txt                    # Список зависимостей
```

## Контакты

Автор: Arseniy Bartenev  
Email: arseniybartenev@gmail.com  

---

### Примечания

- Модель `unitary/toxic-bert` загружается автоматически из библиотеки `transformers` при первом запуске.
- Для воспроизведения результатов достаточно последовательно выполнить все ячейки ноутбука. Обучение BERT‑эмбеддингов на полном датасете может занять продолжительное время; в ноутбуке используется сэмпл из 400 комментариев для демонстрации подхода. При необходимости можно обработать все данные аналогичным образом.
- Предварительно очищенный файл `data_clean_text.csv` позволяет сэкономить около 2 часов на повторных запусках.
